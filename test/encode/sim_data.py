"""
Simulates latent multinomial data based on real data from the 1000 Genomes Project. The data 
consists of 190 haplotype samples of the CEU population (Utah residents with ancestry from Northern 
and Western Europe) for the region ENm010 on chromosome 7, specifically, chr7:26917902-27417901. 
Following [1], we select the SNPs of the ENm010 region such that adjacent SNPs are separated by at 
least 100 base pairs.

1. Gasbarra, D., Kulathinal, S., Pirinen, M., & Sillanpaa, M. J. (2011). Estimating Haplotype 
Frequencies by Combining Data from Large DNA Pools with Database Information. IEEE/ACM Transactions 
on Computational Biology and Bioinformatics, 8(1), 36â€“44. https://doi.org/10.1109/TCBB.2009.71
"""

import numpy as np
from collections import Counter


reg_str = '7_26917902-27417901'
min_sep = 100


def filt(locs, dist):
    """Selects a subset of locations `locs` that are at least `dist` base pairs apart."""
    atleast = 0
    res = []
    for i, loc in enumerate(locs):
        if loc >= atleast:
            res.append(i)
            atleast = loc + dist
    return res


def gen_sim_data(n_pools, n_markers, pool_size, n_datasets, data_dir, min_sep=100):
    """
    Simulate the datasets based on haplotype data stored in `7_26917902-27417901.ped` with marker
    locations `7_26917902-27417901.info`. The haplotype probabilities are written to the file
    `{data_dir}/psize{pool_size}_m{n_markers}_id{dataset_index}.prob`; the simulated allele counts
    are written to the file `{data_dir}/psize{pool_size}_m{n_markers}_id{dataset_index}.data`.

    Parameters
    ----------
    n_pools : int > 0
        Number of pools (data points) per dataset.
    n_markers : int > 0
        Number of markers per dataset.
    pool_size : int > 0
        Number of haplotype samples per pool.
    n_datasets : int > 0
        Number of datasets to simulate.
    data_dir : str
        Directory to store data files at.
    min_sep : int >= 0
        Minimum separation distance between adjacent SNPs selected.

    Returns
    -------
    None
    """

    with open(f'{reg_str}.ped') as fp:
        data = [line.split() for line in fp]

    with open(f'{reg_str}.info') as fp:
        locs = [int(line.split()[0][2:]) for line in fp]

    # each row of `data` corresponds to an individual
    # first 6 entries of each row are not relevant
    # the following entries are alelle pairs for each marker
    # marker locations are stored in `locs` 
    haplotypes = []
    hapids = []
    for tokens in data:
        haplotypes.append(tokens[6::2])
        hapids.append(tokens[0] + '_1')
        haplotypes.append(tokens[7::2])
        hapids.append(tokens[0] + '_2')

    hap_arr = np.array(haplotypes)
    pop_size = len(hap_arr) # 190
    assert all(len(set(col)) == 2 for col in hap_arr.T), "SNPs are not biallelic"
    assert hap_arr.shape[1] == len(locs), ("Number of markers haplotyped does not match "
                                           "number of marker locations provided")

    # get markers at least `min_sep` base pairs apart
    loc_idxs = filt(locs, min_sep)
    hap_arr = hap_arr[:,loc_idxs]
    locs = [locs[i] for i in loc_idxs]

    assert n_datasets*n_markers <= len(loc_idxs), (
        "Not enough markers to simulate this many datasets, try decreasing `n_datasets`, "
        "`n_markers`, or `min_sep`"
    )

    # get boolean encoding of SNPs, 0 for major allele, 1 for minor allele
    minor_alleles = []
    for col in hap_arr.T:
        freqs = Counter(col)
        minor_alleles.append(min(freqs.items(), key=lambda x: x[1])[0])
    is_minor = (hap_arr == np.array(minor_alleles)).astype(int)

    # simulate datsets
    for i in range(0, n_datasets):
        idx_list = [i*n_markers+j for j in range(n_markers)]
        # get original haplotype counts
        haps, fs = np.unique(is_minor[:,idx_list], 
                             return_counts=True, axis=0)
        ds_idx = i + 1
        fn_prefix = f'{data_dir}/psize{pool_size}_m{n_markers}_id{ds_idx}'

        # write probabilities
        with open(f'{fn_prefix}.prob', 'w') as fp:
            for h, p in zip(haps, fs/pop_size):
                hstr = ''.join([str(x) for x in h])
                fp.write(f'{hstr} {p}\n')

        # sample multinomial counts and write allele counts
        amat = haps.T
        np.random.seed(ds_idx)
        with open(f'{fn_prefix}.data', 'w') as fp:
            for _ in range(n_pools):
                zvec = np.random.multinomial(pool_size, fs/pop_size)
                yvec = np.dot(amat, zvec).astype(int)

                fp.write(' '.join([str(pool_size)] + [str(y) for y in yvec]))
                fp.write('\n')


def parse_sim_data(fname):
    """
    Parse the data generated by `gen_sim_data`.

    Parameters
    ----------
    fname : string
        Filename containing pool size and observed counts.

    Returns
    -------
    tuple (list[int], list[list[int]])
        2-tuple consisting of (i) a list of pool sizes, and (ii) a list of observed allele counts.
    """
    ns = []
    ys = []

    with open(fname) as fp:
        for line in fp:
            tokens = [int(x) for x in line.split()]
            ns.append(tokens[0])
            ys.append(tokens[1:])

    return ns, ys